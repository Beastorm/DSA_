## Theory:

---

### Question 1: Deriving the Time Complexity of Binary Search: O(log N)

#### <ins>1. The Core Idea: Halving the Problem</ins>

The power of binary search stems from a single principle: **at every step, it eliminates half of the remaining data. ****

Imagine looking for a word in a 1000-page dictionary.

-   *Linear Search (`O(N)`):* You start at page 1, then 2, then 3... In the worst case, you might have to check all 1000 pages.
-   *Binary Search (`O(log N)`):*
    1.  You open to the middle, page 500.
    2.  You see the word you're looking for comes later alphabetically. You instantly *throw away the first 500 pages*. Your problem is now only 500 pages long.
    3.  You open to the middle of the remaining pages (page 750). The word comes earlier. You *throw away the last 250 pages*. Your problem is now only 250 pages long.

With each check, you cut the problem size in half. This is dramatically faster than checking one by one.

#### <ins>2. The Pattern of Reduction</ins>

Let's track the size of the array (our search space) with each step. Let `N` be the initial number of elements.

| Step | Number of Elements Remaining | In terms of N |
| :--- | :--- | :--- |
| 0 (Start) | `N` | `N / 2⁰` |
| 1 | `N / 2` | `N / 2¹` |
| 2 | `N / 4` | `N / 2²` |
| 3 | `N / 8` | `N / 2³` |
| ... | ... | ... |
| `k` | `N / 2ᵏ` | `N / 2ᵏ` |

The search stops when we have only *1* element left to check. So, the process ends at step `k` where:

`N / 2ᵏ = 1`

Our goal is to find `k`, the total number of steps, because the number of steps determines the time complexity.

#### <ins>3. The Mathematical Derivation</ins>

We start with the equation from the final step of our search:

`N / 2ᵏ = 1`

Now, let's solve for `k` (the number of steps):

1.  Multiply both sides by `2ᵏ`:  
    `N = 2ᵏ`  

2.  To solve for the exponent `k`, we use the *logarithm*.  
    The logarithm answers the question: "What power do I need to raise a base to, to get a certain number?"   

    In this case, the question is: "What power `k` must I raise the base `2` to, to get `N`?"   

    The mathematical way to write this is:  
    ```
        log₂ 2ᵏ = log₂ N
     => log₂ 2ᵏ = log₂ N 
     => klog₂ 2 = log₂ N
     => k = log₂ N             as log₂ 2 is 1 
    ```
This proves that the number of steps (`k`) required for binary search is `log₂ N`.  

#### What is a Logarithm?

A logarithm tells you *how many times you can divide a number by a base until you get to 1.*

-   `log₂(16)` asks: "How many times can you divide 16 by 2?"
    -   16 → 8 → 4 → 2 → 1  (That's **4** times). So, `log₂(16) = 4`.
-   `log₂(32)` asks: "How many times can you divide 32 by 2?"
    -   32 → 16 → 8 → 4 → 2 → 1 (That's **5** times). So, `log₂(32) = 5`.

This perfectly matches our binary search algorithm, where we repeatedly divide the array size `N` by `2`.

#### <ins>Conclusion: O(log N)</ins>

-   We've established that the number of operations required is proportional to `log₂ N`.
-   In Big O notation, we abstract away the specific base of the logarithm because the difference between `log₂ N`, `log₁₀ N`, or `ln N` is just a constant factor, and Big O ignores constant factors.
-   Therefore, the time complexity of Binary Search is simplified to:

    *`O(log N)`*

> [!NOTE]
>This logarithmic complexity is what makes binary search incredibly efficient for large datasets. While a linear search on 1 million items could take 1 million operations,
a binary search would take only about *20* operations (`log₂(1,000,000) ≈ 19.9`).

---


