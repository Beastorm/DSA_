## Huffman Encoding (Greedy)

**Problem Statement:**  
Given a string (or a set of characters with frequencies), construct a **Huffman Tree** to generate binary codes for each character such that the **total length of the encoded string is minimized**.

**Rules:**
- Characters with higher frequency get shorter codes.
- No code should be a prefix of another (Prefix Property).

**Task:** Return the Pre-order traversal of the Huffman Tree.

---

### Why Does Huffman Encoding Exist?

### The Problem: Data Size
Computers store characters as fixed-size bits (e.g., ASCII uses 8 bits per character).
- 'a' = 01100001
- 'b' = 01100010

If you have a file with **100,000 characters**, the file size is exactly **800,000 bits**.

### The Observation:
In real text, not all characters appear equally.
- 'e' and 'a' appear all the time.
- 'z' and 'q' appear very rarely.

Why waste 8 bits on 'e' when we use it thousands of times?
Why waste 8 bits on 'z' when we only use it once?

### The Solution: Variable Length Coding:
Huffman Encoding exists to **compress data** by giving:
- **Short codes** to frequent characters.
- **Long codes** to rare characters.

**Result:** The total number of bits required to store the file drops significantly (often by 40-50%). It is the foundation of file compression (like ZIP files).

---

### How Huffman Encoding Works (Sender to Receiver)

Let's say the Sender wants to send the message: **"BEEP"**

### 1. Encoding (The Sender's Job):

The Sender analyzes the frequency of characters in the message (or language).
Suppose our frequency map is:
- **E**: High freq (Short code) -> `0`
- **B**: Medium freq -> `10`
- **P**: Low freq -> `11`

**Message:** "BEEP"
- B -> 10
- E -> 0
- E -> 0
- P -> 11

**Encoded Stream:** `100011` (6 bits)
*(Standard ASCII would be 4 chars * 8 bits = 32 bits. We saved space!)*

The Sender sends:
1. The **Encoded Binary**: `100011`
2. The **Huffman Tree (Key)**: (Usually the frequency table is sent so the receiver can rebuild the tree).

![Huffman Encoding Tree](https://github.com/Beastorm/DSA_/blob/9dff9e74e2543ec4c2cbea21a4e11c8ba89227c1/junk/huffman.png?raw=true)  
*Visual representation of the Huffman Tree constructed for the message "BEEP". Characters with higher frequency ('E') are closer to the root, resulting in shorter binary codes.*

---

### 2. Decoding (The Receiver's Job):

The Receiver gets the stream `100011` and the Tree structure.
The Receiver starts at the **Root** of the tree and walks down:

**Stream:** `1 0 0 0 1 1`

1. Read `1`: Go Right. (Not leaf).
2. Read `0`: Go Left. **Leaf Node 'B' found!** -> Write "B". Reset to Root.
3. Read `0`: Go Left. **Leaf Node 'E' found!** -> Write "E". Reset to Root.
4. Read `0`: Go Left. **Leaf Node 'E' found!** -> Write "E". Reset to Root.
5. Read `1`: Go Right. (Not leaf).
6. Read `1`: Go Right. **Leaf Node 'P' found!** -> Write "P". Reset to Root.

**Decoded Message:** "BEEP"

Because of the **Prefix Property** (no short code is the start of a long code), the Receiver never gets confused about where a character ends.

---

### ðŸ§  Intuition:
To minimize the total length, frequently used characters (like 'e' or 'a') should have very short binary codes (like `0` or `10`), while rare characters (like 'z' or 'q') can have longer codes.

**Greedy Strategy:**
1. Treat every character as a leaf node with a weight equal to its frequency.
2. Put all nodes into a **Min-Heap** (Priority Queue).
3. While there is more than one node in the heap:
   - Extract the two nodes with the **smallest frequencies**.
   - Create a new internal node with weight = sum of the two frequencies.
   - Make the two extracted nodes children of this new node.
   - Push the new node back into the heap.
4. The remaining node is the **Root** of the Huffman Tree.

---

### ðŸ’» Code (C++):

```cpp
#include <iostream>
#include <vector>
#include <queue>
#include <string>

using namespace std;

// Tree Node
struct Node {
    char data;
    int freq;
    Node *left, *right;

    Node(char c, int f) {
        data = c;
        freq = f;
        left = right = nullptr;
    }
};

// Comparator for Min-Heap
struct Compare {
    bool operator()(Node* a, Node* b) {
        return a->freq > b->freq; // Min freq at top
    }
};

// Recursive Pre-order Traversal to print codes
void printCodes(Node* root, string code) {
    if (!root) return;

    // If leaf node, print character and code
    if (root->data != '$') {
        cout << root->data << ": " << code << endl;
    }

    printCodes(root->left, code + "0");
    printCodes(root->right, code + "1");
}

void huffmanCodes(char data[], int freq[], int size) {
    priority_queue<Node*, vector<Node*>, Compare> pq;

    // 1. Create leaf nodes for each character
    for (int i = 0; i < size; i++) {
        pq.push(new Node(data[i], freq[i]));
    }

    // 2. Build the Tree
    while (pq.size() > 1) {
        // Extract the two smallest
        Node* left = pq.top(); pq.pop();
        Node* right = pq.top(); pq.pop();

        // Create internal node ('$' is placeholder)
        Node* top = new Node('$', left->freq + right->freq);
        top->left = left;
        top->right = right;

        pq.push(top);
    }

    // 3. Print Codes
    printCodes(pq.top(), "");
}

int main() {
    char arr[] = { 'a', 'b', 'c', 'd', 'e', 'f' };
    int freq[] = { 5, 9, 12, 13, 16, 45 };
    int size = sizeof(arr) / sizeof(arr[0]);

    huffmanCodes(arr, freq, size);

    return 0;
}
```

### Complexity Analysis:

- **Time Complexity:** **O(N log N)**
  - **Inserting** all `N` characters into the min-heap takes `O(N log N)`.
  - **Building the tree** involves extracting two minimum nodes and inserting one new node `N-1` times. Each extraction and insertion takes `O(log K)` where `K` is the current number of nodes in the heap.
  - The total time complexity is dominated by these heap operations.

- **Space Complexity:** **O(N)**
  - We need to store the Huffman tree nodes. A tree with `N` leaves will have `2N - 1` total nodes.
  - The priority queue also stores up to `N` nodes at once.
